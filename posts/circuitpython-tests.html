---
title: Testing CircuitPython Modules
slug: circuitpython-tests
date: 2019-11-25 13:30:00 UTC
description: A quick hack to make it easy to write tests for CircuitPython modules.
author: Nicholas H.Tollervey
---

<p><a href="https://micropython.org/">MicroPython</a>, a project by my
buddy <a href="http://dpgeorge.net/">Damien George</a>, is a
complete reimplementation of the Python programming language for
microcontrollers and embedded systems. Put simply, it's Python for extremely
small computers (and I once
<a href="http://shop.oreilly.com/product/0636920056515.do">wrote a book about it</a>).
<a href="https://circuitpython.org/">CircuitPython</a>, a friendly fork of
MicroPython, is sponsored by the fantastic folks
at <a href="https://adafruit.com/">Adafruit</a>, a company who make playful and
easy-to-use "hackable" technology while promoting a welcoming, friendly and
diverse community of makers. They are led by legendary founder and electrical
engineer extraordinaire, <a href="http://www.ladyada.net/">Limor "ladyada" Fried</a>.
CircuitPython is MicroPython for Adafruit's line of boards and with a
consistent API for accessing the numerous bits of cool hardware you can use
with such devices.</p>

<p>I was privileged to recently complete a block of work for Adafruit: I've
written a CircuitPython module called <code>adafruit_radio</code> that makes it
easy for
<a href="https://en.wikipedia.org/wiki/Bluetooth">Bluetooth</a> enabled
Adafruit boards to communicate with each other. The API is
a simplified version of the work myself and a number of other volunteers did on
the
<a href="https://microbit-micropython.readthedocs.io/en/v1.0.1/radio.html">equivalent functionality</a>
for the BBC micro:bit (<a href="https://microbit-micropython.readthedocs.io/en/v1.0.1/tutorials/radio.html">here's a tutorial I wrote for the micro:bit
radio</a>, to make electronic "fireflies" blink at each other over
Bluetooth).</p>

<p>In the new Adafruit module, sending a message is as simple as:</p>

<pre><code>from adafruit_radio import Radio
r = Radio()
r.send("Hello")
</code></pre><br/>

<p>Receiving requires a loop (to allow the device to keep checking for
messages), but is equally as simple:</p>

<pre><code>from adafruit_radio import Radio
r = Radio()

while True:
    message = r.receive()
    if message:
        # Do something useful with the message.
        print(message)
</code></pre><br/>

<p>The best model for thinking about this module is that of kids'
walkie-talkies. Each
radio is tuned to a certain channel upon which it broadcasts and receives.
If you send a message, anyone else listening in on that channel and within
range will receive it. You'll also receive messages broadcast on that
channel from others within range. 
This is an ideal network topology because it's both familiar
yet capable since other, more specialised, network topologies can be built on
top of it. There is potential for users to grow from a simple "walkie-talkie"
model of networking to something more sophisticated and of their own
devising.</p>

<p><img src="/static/images/walkie-talkie.jpg" alt="Kids on walkie-talkies"/></p>

<p>The channels in the module are numbered between 0-255 and can be set when
creating a <code>Radio</code> object (the default channel number is 42 in
honour of
<a href="https://en.wikipedia.org/wiki/Douglas_Adams">Douglas Adams</a>, who
saw so much humane potential in new technology yet mischievously warned of the
polluting effect of technology for technology's sake via the inept
work of the
<a href="https://en.wikipedia.org/wiki/Technology_in_The_Hitchhiker%27s_Guide_to_the_Galaxy#Sirius_Cybernetics_Corporation">Sirius Cybernetics Corporation</a>):</p>

<pre><code>from adafruit_radio import Radio
r = Radio(channel=123)
</code></pre><br/>

<p>Alternatively, you can change channel at any time via the <code>Radio</code>
object's <code>configure</code> method (continuing the example above):</p>

<pre><code>r.configure(channel=7)
</code></pre><br/>

<p>Finally, in addition to sending strings of characters it's also possible to
send and receive arbitrary bytes:</p>

<pre><code>from adafruit_radio import Radio
r = Radio()
r.send_bytes(b"Hello")
</code></pre><br/>

<p>Receiving bytes gives you the full context of the message expressed as a
Python tuple consisting of three values: the raw bytes, the RSSI reading (i.e.
strength of the signal, from 0 [max] to -255 [min]), and a timestamp
representing the number (and fraction of) seconds since the device powered up,
as demonstrated in the following REPL based example:</p>

<pre><code>&gt;&gt;&gt; from adafruit_radio import Radio
&gt;&gt;&gt; r = Radio()
&gt;&gt;&gt; r.receive_full()
(b'Hello', -40, 3245.155408037)
</code></pre><br/>

<p>That's it! You can find the code in <a href="https://github.com/ntoll/Adafruit_CircuitPython_Radio">this GitHub repository</a>.
Special mention and thanks must be made to Adafruit's
<a href="http://tannewt.org/">Scott Shawcroft</a> and
<a href="https://danhalbert.org/">Dan Halbert</a> who
wrote the Bluetooth API I used. Because of their
work I was able to create my module with less than a hundred lines of Python
(at time of writing). Thanks chaps!</p>

<p>Armed with this context, I'm going to explain why and how I created a
comprehensive test suite for the <code>adafruit_radio</code> module.</p>

<p>I'd summarise my approach to testing as follows:</p>

<ul>
    <li>Testing is fundamental for creating and maintaining well designed
    software. My experience is that it tends to produce code that is both
    simple and easy to understand because nobody wants to write complicated
    tests to exercise equally complicated code. The process of exercising code
    through tests forces a developer to think carefully about how their code
    is written while having the added benefit of demonstrating it works as
    expected. Simplicity and ease of understanding are
    desirable properties because such code is easier to read, correct and
    maintain and also indicates the author's own clarity of thought (a good
    sign). I also believe it helpful and friendly to write code that's easy
    for others to read and understand (I often imagine my code will be read by
    an intelligent beginner coder, because it forces me to explain and address
    my own assumptions about my code).</li>

    <li>I personally don't practice strict test-driven development, where one
    writes tests before writing the implementation. I prefer to explore,
    improvise, extemporise and play at first. I often try various different
    approaches to the task in hand and regularly re-draft. I'll often seek
    advice and comments from collaborators, colleagues and potential users of
    my code as soon as possible. Therefore, my highest priority when I start a
    new project is making my code simple enough so that it is very easy to
    change. Often this step in the coding process is called a "spike".</li>

    <li>Only when a project settles on a certain architecture, implementation
    or foundation of code do I add tests. I think of this as a sort of
    "hardening" process. When I'm happy with an approach I'll often re-draft
    the exploratory code I've already written, alongside writing tests to
    exercise that specific piece of code. I aim for, and often achieve, 100%
    test coverage (every line of my code is exercised in some way by a test).
    This process allows me to get a feel for how my API works from the point of
    view of a fellow coder encountering it for the first time.</li>

    <li>The hardening has another effect: I've baked in an expectation for how
    the code should behave via the tests. I also make sure my tests are
    commented in such a way that a meaningful intention behind the test is
    revealed. They're also a useful source of information for future users
    and/or maintainers of my code. Finally, and perhaps most importantly, they
    help manage change.</li>

    <li>No useful software is ever finished simply because the universe changes
    (and so must software). Despite our best efforts, software is often
    complicated and it's easy to forget something or not realise how a change
    in one part of the
    code may break another apparently unrelated part. Having a suite of
    tests to check all the aspects of a codebase helps future maintainers make
    changes with confidence.</li>

    <li>Being pragmatic, I sometimes don't follow the playful explorations
    outlined above. If I'm dealing with a well defined or mature protocol
    (for example), I'll quickly settle on an approach, usually based upon
    research into how other folks have solved the same problem, and proceed by
    writing tests based upon the protocol in order to measure the completeness,
    accuracy and progress of my resulting implementation.</li>
</ul>

<p>The problem for developers writing for CircuitPython is that such code is
usually to be run on microcontrollers with certain hardware capabilities. Yet
such code is invariably written on conventional computers running operating
systems such as Windows, OSX or Linux. The only way to know your code works is
to try it on the target device. This is, to say the least, laborious compared
to having the benefits of running an extensive test suite in a matter of
seconds.</p>

<p>Having written my small and simple <code>adafruit_radio</code> module I
found myself missing the benefits of a comprehensive test suite. After asking
around, I found most Python modules for CircuitPython don't have a test suite
and there hadn't been much (if any) exploration for how to address this. Scott
suggested I add what I thought best in terms of testing to my module.</p>

<p>I wanted my solution to meet the following requirements:</p>

<ul>
    <li>It works with existing Python testing tools so non-specialist Python
    developers feel at home and can bring their existing skills to
    CircuitPython with little effort.</li>

    <li>It runs on a conventional computer, because that's where developers do
    the majority of their work. (I'm constantly running and re-running my
    test-suite as I make changes to code.)</li>

    <li>It handles the problem of using CircuitPython-only modules in a
    test-suite run on a conventional computer with standard Python.</li>
</ul>

<p>I decided to focus on using an existing, well known and mature Python
testing tool called <a href="http://pytest.org/en/latest/">PyTest</a> (the
creation of another friend of mine, the extraordinarily prolific and very
thoughtful <a href="https://holgerkrekel.net/">Holger Krekel</a>). The
advantage of using PyTest is that it has a large number of plug-ins that are
both useful and familiar to a large number of Python programmers. One such
plug-in I use a lot is the
<a href="https://github.com/pytest-dev/pytest-cov">Pytest coverage tool</a>,
which makes it easy to spot areas of a code base that are <em>not</em> 
exercised by a test suite. PyTest also has a well defined mechanisms to extend
it to work in specialist testing situations (such as our own CircuitPython
based context).</p>

<p>As far as I was concerned, using PyTest met the first two of my self-imposed
requirements. I was left with the final problem of dealing with CircuitPython
only modules that wouldn't work on a conventional computer.</p>

<p>This is where I need to introduce the concept of "mocking" in a test suite
(as in "mocked up" rather than poking fun). Mocking is a way to replace parts
of your system under test with "mocked up" objects and then make assertions
about how such objects have been used. Thanks to another friend of mine (the
huge hearted, funny and rather hairy
<a href="http://www.voidspace.org.uk/">Michael Foord</a>), mocking is built
right into Python's standard library.</p>

<p>My idea was simple: automatically mock away those parts of CircuitPython
that don't work on a conventional computer. Such objects give the developer a
way to check and ensure the module under test is working as expected with
CircuitPython. It's even possible to specify how such mock objects should
behave under certain conditions (such as when they may be the source of some
sort of data which the module under test will use). However, this aspect of
mocking should be used with great care -- more on which later.</p>

<p>If a developer creates a <code>conftest.py</code> file in their test suite
PyTest will import it before running any of the test code and use various
functions found therein to configure the test suite. For example, if PyTest
finds a function called <code>pytest_runtest_setup</code> in the
<code>conftest.py</code> file, then this function will always be called
immediately prior to any test function. Just what we need!</p>

<p>My <a href="https://github.com/ntoll/Adafruit_CircuitPython_Radio/blob/master/tests/conftest.py"><code>conftest.py file</code></a>
is very short and simply mocks away named aspects of CircuitPython which cannot
be run on a conventional computer immediately before any test is run, via the
aforementioned <code>pytest_runtest_setup</code> convention.</p>

<p>It means I can write conventional looking PyTest based unit tests like the
following:</p>

<pre><code>def test_radio_receive_full_no_messages(radio):
    """
    If no messages are detected by receive_full then it returns None.
    """
    radio.ble.start_scan.return_value = []
    assert radio.receive_full() is None
    radio.ble.start_scan.assert_called_once_with(
        adafruit_radio.AdafruitRadio, minimum_rssi=-255, timeout=1
    )
    radio.ble.stop_scan.assert_called_once_with()
</pre></code><br/>

<p>Some things you should know: <code>radio.ble</code> is a mocked away part of
CircuitPython. As a result, on the first line of my test function, I've been
able to tell the mock that the result of calling the <code>start_scan</code>
method is an empty list. Then I can assert that the method I want to test (the
<code>radio.receive_full</code> method returns <code>None</code> in this
context. Furthermore, I'm able to check in the final two statements of the
function that the <code>start_scan</code> method was called with the expected
arguments, and that an additional <code>stop_scan</code> method was called
too.</p>

<p>When I run the test suite, I see something like this:</p>

<pre><code>$ pytest --cov-report term-missing --cov=adafruit_radio tests/
============================= test session starts ==============================
platform linux -- Python 3.7.5, pytest-5.3.0, py-1.8.0, pluggy-0.13.0
rootdir: /home/ntoll/src/adafruit_radio
plugins: cov-2.8.1
collected 12 items                                                             

tests/test_adafruit_radio.py ............                                [100%]

----------- coverage: platform linux, python 3.7.5-final-0 -----------
Name                Stmts   Miss  Cover   Missing
-------------------------------------------------
adafruit_radio.py      61      0   100%


============================== 12 passed in 0.09s ==============================
</code></pre><br/>

<p>Note all the feedback about code coverage..! Neat, huh?</p>

<p>A mock object, by its very nature, is a mock-up of something else... it's
not the real thing..! So what happens when the real thing (that has been
mocked-up in the test suite) changes? For instance let's imagine that the
result of a call to <code>start_scan</code> is no longer an empty list, but
something else. The tests will still pass because the mocked-up object doesn't
reflect the real object, yet when the module under test is used on a real
device with the changed version of CircuitPython then it won't work
correctly.</p>

<p>This is obviously not a good situation and why I mention mocks should be
used with great care and attention.</p>

<p>The most obvious solution is for the developer in charge of the test
suite to be careful and check API updates in the release notes of the modules
being mocked away. However, this becomes a burden if the test suite mocks away
a huge number of modules. It's also open to human error.</p>

<p>There are several ways to mitigate this problem, but because it's early days
I've not been able to investigate these potential solutions properly. The best
I can do at this point in time is shrug my shoulders, say things are under
construction and invite folks to dive in and help. Our community would
certainly be enriched by such collaborations.</p>

<p>In conclusion, I'm quite pleased with this first step in equipping
CircuitPython modules with comprehensive test suites. Yet there's still plenty
to do -- most notably, ways to address the problems mentioned with mocking.</p>

<p>As always, comments, constructive criticism and ideas expressed in a
friendly, collaborative and supportive manner are most welcome.</p>

<p>Over to you... :-)</p>

